---
title: BACS-hw17-107070004
output:
  pdf_document:
mainfont: LiberationSerif
sansfont: LiberationSans
monofont: LiberationMono
---

```{r, include=FALSE}
install.packages("rpart",repos = "http://cran.us.r-project.org")
library(rpart)
install.packages("rpart.plot",repos = "http://cran.us.r-project.org")
library(rpart.plot)
```

helper: teams

This week, we will look at a dataset of US health insurance premium charges. We will build models that can predict what someone’s insurance charges might be, given several factors about them. You download the dataset, and find more information about it, at the Kaggle platform where machine learning people like to host challenges and share datasets: https://www.kaggle.com/datasets/teertha/ushealthinsurancedataset

# Question 1) Create some explanatory models to learn more about charges:

## a. Create an OLS regression model and report which factors are significantly related to charges

```{r}
insurance <- read.csv("./insurance.csv")
insurance_lm <- lm(charges ~ age + sex + bmi + children + smoker + region, data=insurance)
summary(insurance_lm)
```

## b. Create a decision (regression) tree with default parameters

### (i) Plot a visual representation of the tree

```{r}
insurance_tree <- rpart(charges ~ age + sex + bmi + children + smoker + region, data=insurance)
insurance_tree
rpart.plot(insurance_tree)
```

### (ii) How deep is the tree (see nodes with “decisions” – ignore the leaves at the bottom)

2

### (iii) How many leaf groups does it suggest to bin the data into?

4

### (iv) What is the average charges of each leaf group?

### (v) What conditions (decisions) describe each group?

table for the answers of (iv) & (v)

| the condition of leaf group | average charges |
| :----: | :----: |
| smoker=yes, age<42.5=yes | 5398.850 |
| smoker=yes, age<42.5=no | 12299.890 |
| smoker=no, bmi<30.01=yes | 21369.220 |
| smoker=no, bmi<30.01=no | 41692.810 |

# Question 2) Let’s use LOOCV to see how our models perform predictively

```{r}
fold_i_pe <- function(i, k, model, dataset, outcome) {
  folds <- cut(1:nrow(dataset), breaks=k, labels=FALSE)
  test_indices <- which(folds==i)
  test_set <- dataset[test_indices, ]
  train_set <- dataset[-test_indices, ]
  trained_model <- update(model, data = train_set)
  predictions <- predict(trained_model, test_set)
  dataset[test_indices, outcome] - predictions
}

k_fold_mse <- function(model, dataset, outcome, k){
    shuffled_indicies <- sample(1:nrow(dataset))
    dataset <- dataset[shuffled_indicies,]
    fold_pred_errors <- sapply(1:k, function(kth) {
        fold_i_pe(kth, k, model, dataset, outcome)
      })
    pred_errors <- unlist(fold_pred_errors)
    mse <- function(errs){
      mean(errs^2)
    }
    c(is = mse(residuals(model)), oos = mse(pred_errors))
}
```

## a. What is the RMSEoos for the OLS regression model?

```{r}
sqrt(k_fold_mse(insurance_lm, insurance, "charges", 10)[2])
```
## b. What is the RMSEoos for the decision tree model?

```{r}
sqrt(k_fold_mse(insurance_tree, insurance, "charges", 10)[2])
```

# Question 3) Let’s see if bagging helps our models

## a. Write bagged_learn(…) and bagged_predict(…) functions using the hints in the class notes and help from your classmates on Teams. Feel free to share your code generously on Teams to get feedback, or ask others for help.

```{r}
set.seed(27935752)
train_indices <- sample(1:nrow(insurance), size = 0.8*nrow(insurance))
train_set <- insurance[train_indices,]
test_set <- insurance[-train_indices,]

mse_oos<-function(actuals, preds) {
  sqrt(mean( (actuals-preds)^2))
  }
```

```{r}
bagged_learn <- function(model, dataset, b=100){
	lapply(1:b,\(i) {
    boot_index <- sample(nrow(dataset), replace = TRUE)
    boot_dataset <- dataset[boot_index,]
	  # Get a bootstrapped (resampled w/ replacement) dataset
	  update(model, data = boot_dataset)
	  # Return a retrained(updated) model
	 })
}
bagged_predict <- function(bagged_learning, new_data) {
  b <- length(bagged_learning)
  predictions <- lapply(1:b,\(i) {
    pred <- predict(bagged_learning[[i]], new_data)
  })
	# get b predictions of new_data
	as.data.frame(predictions) |> apply(1, mean)
	# apply a mean over the columns of predictions
}
```

## b. What is the RMSEoos for the bagged OLS regression?

```{r}
bagged_list <- bagged_learn(insurance_lm, train_set)
bagged_predict_list <- bagged_predict(bagged_list, test_set)
mse_oos(test_set$charges, unlist(bagged_predict_list))
```

## c. What is the RMSEoos for the bagged decision tree?

```{r}
bagged_list <- bagged_learn(insurance_tree, train_set)
bagged_predict_list <- bagged_predict(bagged_list, test_set)
mse_oos(test_set$charges, unlist(bagged_predict_list))
```

# Question 3) Let’s see if boosting helps our models

## a. Write boosted_learn(…) and boosted_predict(…) functions using the hints in the class notes and help from your classmates on Teams. Feel free to share your code generously on Teams to get feedback, or ask others for help.

```{r}
boosted_learn <- function(model, dataset, n=100, rate=0.1){
  predictors <- dataset[,1:6] # get data frame of only predictor variables
  res <-dataset[,7] # get vector of actuals to start
  
  models <-list()
  # Initialize residuals and models
  
  for(i in 1:n) {
    this_model<-update(model, data =cbind(charges=res, predictors))
    res <- res - (rate)*predict(this_model)
    # update residuals with learning rate
    models[[i]] <-this_model
    # Store model
  }
  list(models=models, rate=rate)
}
boosted_predict <- function(boosted_learning, new_data) {
  boosted_models <- boosted_learning$models
  rate <- boosted_learning$rate
  n <- length(boosted_learning$models)
  predictions <- lapply(1:n, \(i){
    rate*predict(boosted_models[[i]], new_data)
  })
  # get predictions of new_data from each model
  pred_frame <- as.data.frame(predictions) |> unname()
  apply(pred_frame, 1, sum)
}
```

## b. What is the RMSEoos for the boosted OLS regression?

```{r}
boosted_list <- boosted_learn(insurance_lm, train_set)
boosted_predict_list <- boosted_predict(boosted_list, test_set)
mse_oos(test_set$charges, unlist(boosted_predict_list))
```

## c. What is the RMSEoos for the boosted decision tree?

```{r}
boosted_list <- boosted_learn(insurance_tree, train_set)
boosted_predict_list <- boosted_predict(boosted_list, test_set)
mse_oos(test_set$charges, unlist(boosted_predict_list))
```

# Question 4) Let’s engineer the best predictive decision trees. Let’s repeat the bagging and boosting decision tree several times to see what kind of base tree helps us learn the fastest. Report the RMSEoos at each step.

## a. Repeat the bagging of the decision tree, using a base tree of maximum depth 1, 2, … n while the RMSEoos keeps dropping; stop when the RMSEoos has started increasing again.

```{r}
bagged_lm_algo <- function(tree){
  bagged_list <- bagged_learn(tree, train_set)
  bagged_predict_list <- bagged_predict(bagged_list, test_set)
  mse_oos(test_set$charges, unlist(bagged_predict_list))
}

num <- 1
pre_oos <- 100000000
oos <- 100000000
while (pre_oos >= oos) {
  pre_oos <<- oos
  old_tree_stump <- rpart(charges ~ age + sex + bmi + children + smoker + region, data=insurance, cp=0, maxdepth=num)
  oos <<- bagged_lm_algo(old_tree_stump)
  cat(num, ":", oos, "\n")
  num <<- num + 1
}
```

## b. Repeat the boosting of the decision tree, using a base tree of maximum depth 1, 2, … n while the RMSEoos keeps dropping; stop when the RMSEoos has started increasing again.

```{r}
boosted_lm_algo <- function(tree){
  boosted_list <- boosted_learn(tree, train_set)
  boosted_predict_list <- boosted_predict(boosted_list, test_set)
  mse_oos(test_set$charges, unlist(boosted_predict_list))
}

num <- 1
pre_oos <- 100000000
oos <- 100000000
while (pre_oos >= oos) {
  pre_oos <<- oos
  old_tree_stump <- rpart(charges ~ age + sex + bmi + children + smoker + region, data=insurance, cp=0, maxdepth=num)
  oos <<- boosted_lm_algo(old_tree_stump)
  cat(num, ":", oos, "\n")
  num <<- num + 1
}
```